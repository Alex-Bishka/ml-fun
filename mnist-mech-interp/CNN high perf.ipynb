{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a143f2-eb48-4c7b-b9ce-3e199df0784b",
   "metadata": {},
   "source": [
    "# CNN Aiming for Higfher Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d052cb5-b1c1-475d-9c69-0ec947f8dea7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69f4af4-73d5-4e7d-a5a0-7d79842638a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import load_images, load_labels, visualize_image, get_edges, generate_intermediate_edge_labels, horizontal_kernel, vertical_kernel, \\\n",
    "    load_intermediate_labels, generate_intermediate_curve_labels, save_intermediate_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e2da00-7210-42af-89a4-fc35c1f1be06",
   "metadata": {},
   "source": [
    "## Set Device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b92178e-287b-4c21-983f-5368ed26ef50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"We will be using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeafcd7-690b-4be2-9698-eefbbe52c072",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91577e84-66b4-436d-9b0d-676589396ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_images = load_images(\"./data/train-images-idx3-ubyte/train-images-idx3-ubyte\")\n",
    "train_labels = load_labels(\"./data/train-labels-idx1-ubyte/train-labels-idx1-ubyte\")\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels,\n",
    "    test_size=1/6,  # 10k validation\n",
    "    stratify=train_labels,\n",
    "    random_state=42  # for reproducibility\n",
    ")\n",
    "\n",
    "# test data\n",
    "test_images = load_images(\"./data/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\")\n",
    "test_labels = load_labels(\"./data/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9c8e9-1d4d-4208-bdf5-220c6c02fdfc",
   "metadata": {},
   "source": [
    "### Intermediate Data Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a5e527f-c772-410d-a1fb-eed47cc5e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horizontal_image_labels = load_intermediate_labels(\"train_horizontal_image_labels.pkl\")\n",
    "val_horizontal_image_labels = load_intermediate_labels(\"val_horizontal_image_labels.pkl\")\n",
    "test_horizontal_image_labels = load_intermediate_labels(\"test_horizontal_image_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c6499b5-2b97-4dc5-9b30-2092d4185fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vertical_image_labels = load_intermediate_labels(\"train_vertical_image_labels.pkl\")\n",
    "val_vertical_image_labels = load_intermediate_labels(\"val_vertical_image_labels.pkl\")\n",
    "test_vertical_image_labels = load_intermediate_labels(\"test_vertical_image_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab7791-8746-4fa4-b042-ef94f52c4e52",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646bd4b4-90cd-4ffb-a935-2bc1a4e01107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,     # 1 channel for grayscale images\n",
    "                  out_channels=32,                # 32 kernels/filters, so 32 output channels\n",
    "                  kernel_size=3,                  # 3x3 convolutional kernel\n",
    "                  stride=1,                       # move the kernel 1 pixel at a time\n",
    "                  padding=1)                      # pad the input so the output size remains 28x28\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # this will reduce the dimensions by a factor of 2\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32,   \n",
    "                  out_channels=64,                \n",
    "                  kernel_size=3,                 \n",
    "                  stride=1,                      \n",
    "                  padding=1)                     \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  \n",
    "        \n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.activation_function = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutional layer 1\n",
    "        conv_out = self.conv1(x)\n",
    "        conv_act = self.activation_function(conv_out)\n",
    "\n",
    "        # pooling layer 1\n",
    "        pool_out = self.pool1(conv_act)\n",
    "\n",
    "        # convolutional layer 2\n",
    "        conv_out2 = self.conv2(pool_out)\n",
    "        conv_act2 = self.activation_function(conv_out2)\n",
    "\n",
    "        # pooling layer 2\n",
    "        pool_out2 = self.pool2(conv_act2)\n",
    "\n",
    "        # hidden layer\n",
    "        fc1_in = pool_out2.view(pool_out2.size(0), -1)\n",
    "        fc1_out = self.fc1(fc1_in)\n",
    "        fc1_act = self.activation_function(fc1_out)\n",
    "\n",
    "        # classification\n",
    "        classification_out = self.fc2(fc1_act)\n",
    "        \n",
    "        return classification_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d4de8c3-9b75-411f-9194-dde880b071a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a70e39a6-e74b-49d5-b47f-e8ea1dfec4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "# loss functions\n",
    "classification_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizers\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a8cc32-342c-48ac-9295-992b3cf6e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights (to compare below): [[[ 0.2548462   0.27666932 -0.07809083]\n",
      "  [ 0.30620378 -0.07303452  0.06726357]\n",
      "  [-0.16228501  0.19576089  0.29384765]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model weights (to compare below): {model.conv1.weight[0].detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e14a7-cd15-4aa2-9c24-433b7291ef92",
   "metadata": {},
   "source": [
    "What we should see from the above weight matrix output, to verify reproducibility:\n",
    "\n",
    "```\n",
    "Model weights (to compare below): [[[ 0.2548462   0.27666932 -0.07809083]\n",
    "  [ 0.30620378 -0.07303452  0.06726357]\n",
    "  [-0.16228501  0.19576089  0.29384765]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f2994-1874-438f-a4bd-41fbd8a12309",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4b9565-2d0f-437e-9c2c-96a7a3577c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDataset(Dataset):\n",
    "    def __init__(self, images, labels, horizontal_edges, vertical_edges):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.horizontal_edges = horizontal_edges\n",
    "        self.vertical_edges = vertical_edges\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.images) == len(self.labels)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.from_numpy(self.images[idx].copy()).unsqueeze(0).float()\n",
    "        \n",
    "        label = torch.tensor(self.labels[idx].copy(), dtype=torch.long)\n",
    "        horizontal_edge = torch.from_numpy(self.horizontal_edges[idx].copy()).unsqueeze(0).float()\n",
    "        vertical_edge = torch.from_numpy(self.vertical_edges[idx].copy()).unsqueeze(0).float()\n",
    "\n",
    "        return image, label, horizontal_edge, vertical_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0311bf-6964-4ad0-8e28-983d56ba27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility on training\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "generator = torch.Generator().manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581a291f-d3c0-496e-9cda-2e6937d9417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train_dataset = EdgeDataset(train_images, train_labels, train_horizontal_image_labels, train_vertical_image_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, worker_init_fn=seed_worker, generator=generator)\n",
    "\n",
    "# validation data\n",
    "val_dataset = EdgeDataset(val_images, val_labels, val_horizontal_image_labels, val_vertical_image_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)  # larger batch size for faster validation\n",
    "\n",
    "# test data\n",
    "test_dataset = EdgeDataset(test_images, test_labels, test_horizontal_image_labels, test_vertical_image_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ade7f551-2850-482a-80c2-99c6694be0e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  Train Loss: 0.2844\n",
      "  Val Loss: 0.0626 | Val Acc: 98.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "  Train Loss: 0.0545\n",
      "  Val Loss: 0.0679 | Val Acc: 98.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "  Train Loss: 0.0400\n",
      "  Val Loss: 0.0678 | Val Acc: 98.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "  Train Loss: 0.0314\n",
      "  Val Loss: 0.0572 | Val Acc: 98.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "  Train Loss: 0.0325\n",
      "  Val Loss: 0.0518 | Val Acc: 98.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "  Train Loss: 0.0211\n",
      "  Val Loss: 0.0628 | Val Acc: 98.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "  Train Loss: 0.0219\n",
      "  Val Loss: 0.0724 | Val Acc: 98.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "  Train Loss: 0.0167\n",
      "  Val Loss: 0.0743 | Val Acc: 98.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "  Train Loss: 0.0198\n",
      "  Val Loss: 0.0847 | Val Acc: 98.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "  Train Loss: 0.0165\n",
      "  Val Loss: 0.0806 | Val Acc: 98.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "  Train Loss: 0.0165\n",
      "  Val Loss: 0.1055 | Val Acc: 98.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "  Train Loss: 0.0160\n",
      "  Val Loss: 0.1077 | Val Acc: 98.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "  Train Loss: 0.0139\n",
      "  Val Loss: 0.0929 | Val Acc: 98.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "  Train Loss: 0.0113\n",
      "  Val Loss: 0.1310 | Val Acc: 98.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "  Train Loss: 0.0153\n",
      "  Val Loss: 0.1305 | Val Acc: 98.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "  Train Loss: 0.0124\n",
      "  Val Loss: 0.1073 | Val Acc: 98.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "  Train Loss: 0.0158\n",
      "  Val Loss: 0.0963 | Val Acc: 98.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "  Train Loss: 0.0136\n",
      "  Val Loss: 0.1182 | Val Acc: 98.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "  Train Loss: 0.0049\n",
      "  Val Loss: 0.1185 | Val Acc: 98.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "  Train Loss: 0.0178\n",
      "  Val Loss: 0.1695 | Val Acc: 98.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "loss_factor = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training Phase ---\n",
    "    model.train()  # set the model to training mode - this is currently a no-op\n",
    "    train_loss = 0.0\n",
    "\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Train]\", leave=False)\n",
    "    for batch in train_bar:\n",
    "        # deconstruct batch items\n",
    "        images, labels, _, _ = batch\n",
    "        images, labels = images.to(device).float(), labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        classification_out  = model(images)\n",
    "        \n",
    "        # --- Loss and Backprop ---\n",
    "\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # classification loss\n",
    "        classification_loss = classification_loss_fn(classification_out, labels)\n",
    "\n",
    "        # total loss\n",
    "        total_loss = classification_loss\n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # update progress\n",
    "        train_loss += total_loss.item()\n",
    "        train_bar.set_postfix(loss=total_loss.item())\n",
    "\n",
    "    \n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Val]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in val_bar:\n",
    "            # deconstruct\n",
    "            images, labels, _, _ = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            classification_out = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = classification_loss_fn(classification_out, labels)\n",
    "\n",
    "            # calculate metrics\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(classification_out, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # epoch stats\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42527bf0-9f10-4c6e-a59a-961abd0839fc",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7e75023-86fe-4663-8a22-301f92a274f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|█████████████████████████████████| 79/79 [00:00<00:00, 298.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 98.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # again currently a no-op\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(test_loader, desc=f\"Evaluation\")\n",
    "    for batch in test_bar:\n",
    "        images, labels, _, _ = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        classification_out = model(images)\n",
    "\n",
    "        # stats\n",
    "        _, predicted = torch.max(classification_out, 1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e3471-4b74-467c-b3f9-2fd3c35ffbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
