{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84207c44-9c22-4853-943c-5a6cb08bdbdf",
   "metadata": {},
   "source": [
    "# Load Model For Genception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b67228-330c-480e-99b5-cb4001e89013",
   "metadata": {},
   "source": [
    "## SAE Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250d7778-885a-4a6d-9bd2-ddbcb9a27be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4a0ba-710d-4882-9bd0-f948e9f6fb9d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4018f1-cb83-4f0b-90db-0f48aad1fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models_and_data.nn import NeuralNetwork\n",
    "from models_and_data.sae import SparseAutoencoder\n",
    "from models_and_data.edgedataset import EdgeDataset\n",
    "\n",
    "from models_and_data.model_helpers import (evaluate_and_gather_activations, get_sublabel_data, \n",
    "    get_top_N_features, extract_activations, load_intermediate_labels, seed_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbef66c-0819-4e4f-9fb7-346b8b786a6b",
   "metadata": {},
   "source": [
    "## Set Device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f93931-772a-4720-b394-0cff7884a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"We will be using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b553d6d-7e3a-4973-a472-3c735df1b699",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070db857-3892-4a37-b24a-b3f8a8d7bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_images = load_intermediate_labels(\"./intermediate-labels/first_layer/train_images.pkl\")\n",
    "train_labels = load_intermediate_labels(\"./intermediate-labels/first_layer/train_labels.pkl\")\n",
    "\n",
    "# test data\n",
    "test_images = load_intermediate_labels(\"./intermediate-labels/first_layer/test_images.pkl\")\n",
    "test_labels = load_intermediate_labels(\"./intermediate-labels/first_layer/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59db04c-2352-435f-8b78-df59a7533489",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23752356-6fba-456a-bab9-94901a6aa0f7",
   "metadata": {},
   "source": [
    "## Model Result Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffaa23b1-17ba-4dad-9832-0ddb1bcb550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "if device.type.lower() == \"cpu\":\n",
    "    NUM_WORKERS = 0\n",
    "\n",
    "# training data\n",
    "train_dataset = EdgeDataset(train_images, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                          worker_init_fn=seed_worker, generator=generator, pin_memory=True)\n",
    "\n",
    "# test data\n",
    "test_dataset = EdgeDataset(test_images, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5514d7d2-8165-411a-8e1d-a6dcb6883dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_baseline = NeuralNetwork().to(device)\n",
    "model_F0 = NeuralNetwork().to(device)\n",
    "\n",
    "sae_hidden_one_baseline = SparseAutoencoder(input_size=16, hidden_size=HIDDEN_SIZE).to(device)\n",
    "sae_hidden_one_F0 = SparseAutoencoder(input_size=16, hidden_size=HIDDEN_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a44cea1-a15c-441d-b3ed-796353156bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path = \"./SAE-Results/256-0.75/results/baseline/model_state_dict.pth\"\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model_baseline.load_state_dict(checkpoint['model_state_dict'])\n",
    "sae_hidden_one_baseline.load_state_dict(checkpoint['sae_one_state_dict'])\n",
    "\n",
    "best_model_path = \"./SAE-Results/256-0.75/results/F1/models/256_mask_0.29/256_mask/best_model_lf_0.02.pth\"\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model_F0.load_state_dict(checkpoint['model_state_dict'])\n",
    "sae_hidden_one_F0.load_state_dict(checkpoint['sae_one_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b96637-4722-4e22-914b-cb9d9a8f09d2",
   "metadata": {},
   "source": [
    "# Some Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cdd8c88-457b-4337-83bf-cb51bcb0b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Activations: 100%|████████████████████████████████████████| 782/782 [00:01<00:00, 601.62it/s]\n"
     ]
    }
   ],
   "source": [
    "activation_data_baseline = extract_activations(\n",
    "    data_loader=train_loader,\n",
    "    model=model_baseline,\n",
    "    sae_one=sae_hidden_one_baseline,\n",
    "    sae_two=sae_hidden_one_baseline,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f4a64c-5ec8-44f9-b1b8-b74203db11c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Activations: 100%|████████████████████████████████████████| 782/782 [00:01<00:00, 638.85it/s]\n"
     ]
    }
   ],
   "source": [
    "activation_data_baseline = extract_activations(\n",
    "    data_loader=train_loader,\n",
    "    model=model_F0,\n",
    "    sae_one=sae_hidden_one_F0,\n",
    "    sae_two=sae_hidden_one_F0,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837f6c6-3b85-4512-9f46-5a9f73926833",
   "metadata": {},
   "source": [
    "## Comparing Bias w/Recon/H1\n",
    "\n",
    "Here we are comparing average decoded vector with the average hidden vector and the bias vector from the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c530554-d781-40c4-bd99-f4d69e531425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity b/w decoder bias vector baseline and decoder bias vector F0: 0.9333\n"
     ]
    }
   ],
   "source": [
    "b_d_baseline = sae_hidden_one_baseline.decoder.bias.cpu()\n",
    "b_d_F0 = sae_hidden_one_F0.decoder.bias.cpu()\n",
    "\n",
    "cos_sim = nn.CosineSimilarity(dim=0)\n",
    "t1t2_sim = cos_sim(b_d_baseline, b_d_F0).mean()\n",
    "\n",
    "print(f\"Similarity b/w decoder bias vector baseline and decoder bias vector F0: {round(t1t2_sim.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f679f-90ed-4533-824e-6e92be234a9e",
   "metadata": {},
   "source": [
    "## Comparing Model with Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff9896b7-4293-45f1-a286-8aae7308086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_act_path = \"./SAE-Results/256-0.75/features/F0/256_mask.pkl\"\n",
    "recon_max_sparse_act_one = load_intermediate_labels(recon_act_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3da9d5a-e08b-46ec-9256-240a1f88e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = torch.from_numpy(np.mean(np.squeeze(np.array(recon_max_sparse_act_one)), axis=0)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "470b07c9-1b84-4756-9cf3-8e71b773cf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(target_vector, b_d_baseline).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f8c42db-e317-415c-88a8-b2903e1a2a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9333, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(target_vector, b_d_F0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a56e5ff2-7522-43ae-8236-27c318278eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_act_path = \"./SAE-Results/256-0.75/features/F0/256_mask.pkl\"\n",
    "recon_max_sparse_act_one = load_intermediate_labels(recon_act_path)\n",
    "target_vector_f0 = torch.from_numpy(np.mean(np.squeeze(np.array(recon_max_sparse_act_one)), axis=0)).float()\n",
    "\n",
    "recon_act_path_two = \"./SAE-Results/256-0.75/features/F2/256_mask_0.29_256_mask_0.02/256_mask.pkl\"\n",
    "recon_max_sparse_act_one_two = load_intermediate_labels(recon_act_path_two)\n",
    "target_vector_f1 = torch.from_numpy(np.mean(np.squeeze(np.array(recon_max_sparse_act_one_two)), axis=0)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8df4a8ce-e2cd-4e2a-8aa6-d7d275cb9d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9332)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(target_vector_f0, target_vector_f1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299c1390-5cd7-459d-a6d0-1d785490cbe6",
   "metadata": {},
   "source": [
    "## Exploring Weight Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080227c-cc6e-4bd5-91f6-016ef22fef0b",
   "metadata": {},
   "source": [
    "### Decoding the Mean Sparse Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15b94e-8898-4866-912c-99000956e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_one_w = sae_hidden_one.decoder.weight.cpu()\n",
    "sparse_vector_avg = torch.from_numpy(np.mean(activation_data[\"sparse_one\"], axis=0)).float().unsqueeze(1)\n",
    "\n",
    "W_dS_avg = sae_one_w @ sparse_vector_avg\n",
    "recon_avg = W_dS_avg + b_d.unsqueeze(1)\n",
    "\n",
    "sim1 = cos_sim(recon_avg, b_d).mean()\n",
    "sim2 = cos_sim(recon_avg, avg_hidden_vector).mean()\n",
    "sim3 = cos_sim(recon_avg, avg_recon_vector).mean()\n",
    "\n",
    "print(f\"Similiarity b/w reconstructed average and decoder bias vector: {round(sim1.item(), 4)}\")\n",
    "print(f\"Similiarity b/w reconstructed average and average hidden activations: {round(sim2.item(), 4)}\")\n",
    "print(f\"Similiarity b/w reconstructed average and average recon vector: {round(sim3.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b69bc-d4ff-404c-9365-bf7674382349",
   "metadata": {},
   "source": [
    "### An Example of One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd980fc0-7b5e-4983-a30a-0ef68c5f5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vector_ex = torch.from_numpy(activation_data[\"sparse_one\"][0]).float().unsqueeze(1)\n",
    "\n",
    "W_dS_ex = sae_one_w @ sparse_vector_ex\n",
    "recon_ex = W_dS_ex + b_d.unsqueeze(1)\n",
    "\n",
    "sim1_ex = cos_sim(recon_ex, b_d).mean()\n",
    "sim2_ex = cos_sim(recon_ex, avg_hidden_vector).mean()\n",
    "sim3_ex = cos_sim(recon_ex, avg_recon_vector).mean()\n",
    "\n",
    "print(f\"Similiarity b/w reconstructed average and decoder bias vector: {round(sim1_ex.item(), 4)}\")\n",
    "print(f\"Similiarity b/w reconstructed average and average hidden activations: {round(sim2_ex.item(), 4)}\")\n",
    "print(f\"Similiarity b/w reconstructed average and average recon vector: {round(sim3_ex.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d15553-5c84-46d5-94ca-e6100f94f28e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
