{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84207c44-9c22-4853-943c-5a6cb08bdbdf",
   "metadata": {},
   "source": [
    "# Load Model For Genception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b67228-330c-480e-99b5-cb4001e89013",
   "metadata": {},
   "source": [
    "## SAE Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250d7778-885a-4a6d-9bd2-ddbcb9a27be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 1024\n",
    "INPUT_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4a0ba-710d-4882-9bd0-f948e9f6fb9d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4018f1-cb83-4f0b-90db-0f48aad1fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from helpers.nn import NeuralNetwork\n",
    "from helpers.sae import SparseAutoencoder\n",
    "from helpers.edgedataset import EdgeDataset\n",
    "\n",
    "from helpers.model_helpers import (evaluate_and_gather_activations, get_sublabel_data, \n",
    "    get_top_N_features, extract_activations, load_intermediate_labels, seed_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbef66c-0819-4e4f-9fb7-346b8b786a6b",
   "metadata": {},
   "source": [
    "## Set Device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f93931-772a-4720-b394-0cff7884a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"We will be using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b553d6d-7e3a-4973-a472-3c735df1b699",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070db857-3892-4a37-b24a-b3f8a8d7bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_images = load_intermediate_labels(\"./data/FashionMNIST/parsed/train_images.pkl\")\n",
    "train_labels = load_intermediate_labels(\"./data/FashionMNIST/parsed/train_labels.pkl\")\n",
    "\n",
    "# test data\n",
    "test_images = load_intermediate_labels(\"./data/FashionMNIST/parsed/test_images.pkl\")\n",
    "test_labels = load_intermediate_labels(\"./data/FashionMNIST/parsed/test_labels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59db04c-2352-435f-8b78-df59a7533489",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23752356-6fba-456a-bab9-94901a6aa0f7",
   "metadata": {},
   "source": [
    "## Model Result Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffaa23b1-17ba-4dad-9832-0ddb1bcb550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "if device.type.lower() == \"cpu\":\n",
    "    NUM_WORKERS = 0\n",
    "\n",
    "# training data\n",
    "train_dataset = EdgeDataset(train_images, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                          worker_init_fn=seed_worker, generator=generator, pin_memory=True)\n",
    "\n",
    "# test data\n",
    "test_dataset = EdgeDataset(test_images, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5514d7d2-8165-411a-8e1d-a6dcb6883dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "sae_hidden_one = SparseAutoencoder(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE).to(device)\n",
    "sae_hidden_two = SparseAutoencoder(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE).to(device)\n",
    "sae_hidden_three = SparseAutoencoder(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a44cea1-a15c-441d-b3ed-796353156bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path = \"./runs/1024-0.75/results/F0/models/25_top/best_model_lf_0.14.pth\"\n",
    "\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "sae_hidden_one.load_state_dict(checkpoint['sae_one_state_dict'])\n",
    "sae_hidden_two.load_state_dict(checkpoint['sae_two_state_dict'])\n",
    "sae_hidden_three.load_state_dict(checkpoint['sae_three_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c065d-ffaf-48d1-a3cb-6f5447cd93dd",
   "metadata": {},
   "source": [
    "## Verify Correct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde98ef3-1f04-4809-bb0c-75ddfe4da04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model acc: 86.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_results = evaluate_and_gather_activations(model, sae_hidden_one, sae_hidden_two, sae_hidden_three, train_loader, device)\n",
    "Z_train_one, Z_train_two, y_train = train_results[\"Z_one\"], train_results[\"Z_two\"], train_results[\"y\"]\n",
    "\n",
    "test_results = evaluate_and_gather_activations(model, sae_hidden_one, sae_hidden_two, sae_hidden_three, test_loader, device)\n",
    "Z_test_one, Z_test_two, y_test = test_results[\"Z_one\"], test_results[\"Z_two\"], test_results[\"y\"]\n",
    "\n",
    "print(f\"Model acc: {test_results['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b603fa7-25d0-4cd0-955a-9bda271dff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Non-Zero Features per Image (Hidden One): 85.58\n",
      "Average Non-Zero Features per Image (Hidden Two): 110.73\n"
     ]
    }
   ],
   "source": [
    "sparsity_one = np.mean(Z_test_one > 1e-5) * Z_test_one.shape[1]\n",
    "sparsity_two = np.mean(Z_test_two > 1e-5) * Z_test_two.shape[1]\n",
    "print(f\"Average Non-Zero Features per Image (Hidden One): {sparsity_one:.2f}\")\n",
    "print(f\"Average Non-Zero Features per Image (Hidden Two): {sparsity_two:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77538fc-5162-441b-a219-bb1d826f4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Linear Probes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Probe Accuracy (Hidden One): 87.00%\n",
      "Linear Probe Accuracy (Hidden Two): 86.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training Linear Probes ---\")\n",
    "clf_one = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "clf_one.fit(Z_train_one, y_train)\n",
    "acc_one = clf_one.score(Z_test_one, y_test)\n",
    "print(f\"Linear Probe Accuracy (Hidden One): {acc_one:.2%}\")\n",
    "\n",
    "clf_two = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "clf_two.fit(Z_train_two, y_train)\n",
    "acc_two = clf_two.score(Z_test_two, y_test)\n",
    "print(f\"Linear Probe Accuracy (Hidden Two): {acc_two:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b96637-4722-4e22-914b-cb9d9a8f09d2",
   "metadata": {},
   "source": [
    "# Some Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cdd8c88-457b-4337-83bf-cb51bcb0b148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Activations: 100%|██████████████████████████████████████████████| 782/782 [00:01<00:00, 498.95it/s]\n"
     ]
    }
   ],
   "source": [
    "activation_data = extract_activations(\n",
    "    data_loader=train_loader,\n",
    "    model=model,\n",
    "    sae_one=sae_hidden_one,\n",
    "    sae_two=sae_hidden_two,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837f6c6-3b85-4512-9f46-5a9f73926833",
   "metadata": {},
   "source": [
    "## Comparing Bias w/Recon/H1\n",
    "\n",
    "Here we are comparing average decoded vector with the average hidden vector and the bias vector from the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c530554-d781-40c4-bd99-f4d69e531425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity b/w hidden activations and decoder bias vector: 0.8376\n",
      "Similarity b/w hidden activations and reconstructed activations: 1.0\n"
     ]
    }
   ],
   "source": [
    "avg_hidden_vector = torch.from_numpy(np.mean(activation_data['hidden_one'], axis=0)).float()\n",
    "b_d = sae_hidden_one.decoder.bias.cpu()\n",
    "\n",
    "cos_sim = nn.CosineSimilarity(dim=0)\n",
    "t1t2_sim = cos_sim(avg_hidden_vector, b_d).mean()\n",
    "\n",
    "avg_recon_vector = torch.from_numpy(np.mean(activation_data['recon_one'], axis=0)).float()\n",
    "t1t3_sim = cos_sim(avg_hidden_vector, avg_recon_vector).mean()\n",
    "\n",
    "print(f\"Similarity b/w hidden activations and decoder bias vector: {round(t1t2_sim.item(), 4)}\")\n",
    "print(f\"Similarity b/w hidden activations and reconstructed activations: {round(t1t3_sim.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c7a56-fcdb-4cdd-afca-7cf0d69597aa",
   "metadata": {},
   "source": [
    "So, on average, the SAE reconstructs inputs well since the average reconstructed vector and the average hidden direction vector are algined.\n",
    "\n",
    "Neither aligns with our bias vector from the decoder, making our theory about symmetry with S being the 0 vector moot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f679f-90ed-4533-824e-6e92be234a9e",
   "metadata": {},
   "source": [
    "## Comparing Model with Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff9896b7-4293-45f1-a286-8aae7308086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_act_path = \"./runs/1024-0.75/features/F0/25_top.pkl\"\n",
    "recon_max_sparse_act_one = load_intermediate_labels(recon_act_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3da9d5a-e08b-46ec-9256-240a1f88e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = torch.from_numpy(np.mean(np.squeeze(np.array(recon_max_sparse_act_one)), axis=0)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "470b07c9-1b84-4756-9cf3-8e71b773cf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9439)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(target_vector, avg_hidden_vector).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f8c42db-e317-415c-88a8-b2903e1a2a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9440)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(target_vector, avg_recon_vector).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b627ef83-2c32-4108-9efe-232bc30920d4",
   "metadata": {},
   "source": [
    "The student has closely aligned with the master."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299c1390-5cd7-459d-a6d0-1d785490cbe6",
   "metadata": {},
   "source": [
    "## Exploring Weight Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080227c-cc6e-4bd5-91f6-016ef22fef0b",
   "metadata": {},
   "source": [
    "### Decoding the Mean Sparse Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c15b94e-8898-4866-912c-99000956e5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similiarity b/w reconstructed average and decoder bias vector: 0.1524\n",
      "Similiarity b/w reconstructed average and average hidden activations: 0.17\n",
      "Similiarity b/w reconstructed average and average recon vector: 0.1641\n"
     ]
    }
   ],
   "source": [
    "sae_one_w = sae_hidden_one.decoder.weight.cpu()\n",
    "sparse_vector_avg = torch.from_numpy(np.mean(activation_data[\"sparse_one\"], axis=0)).float().unsqueeze(1)\n",
    "\n",
    "W_dS_avg = sae_one_w @ sparse_vector_avg\n",
    "recon_avg = W_dS_avg + b_d.unsqueeze(1)\n",
    "\n",
    "sim1 = cos_sim(recon_avg, b_d).mean()\n",
    "sim2 = cos_sim(recon_avg, avg_hidden_vector).mean()\n",
    "sim3 = cos_sim(recon_avg, avg_recon_vector).mean()\n",
    "\n",
    "print(f\"Similiarity b/w reconstructed average and decoder bias vector: {round(sim1.item(), 4)}\")\n",
    "print(f\"Similiarity b/w reconstructed average and average hidden activations: {round(sim2.item(), 4)}\")\n",
    "print(f\"Similiarity b/w reconstructed average and average recon vector: {round(sim3.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b69bc-d4ff-404c-9365-bf7674382349",
   "metadata": {},
   "source": [
    "### An Example of One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd980fc0-7b5e-4983-a30a-0ef68c5f5d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similiarity b/w reconstructed average and decoder bias vector: 0.0926\n",
      "Similiarity b/w reconstructed average and average hidden activations: 0.1033\n",
      "Similiarity b/w reconstructed average and average recon vector: 0.0998\n"
     ]
    }
   ],
   "source": [
    "sparse_vector_ex = torch.from_numpy(activation_data[\"sparse_one\"][0]).float().unsqueeze(1)\n",
    "\n",
    "W_dS_ex = sae_one_w @ sparse_vector_ex\n",
    "recon_ex = W_dS_ex + b_d.unsqueeze(1)\n",
    "\n",
    "sim1_ex = cos_sim(recon_ex, b_d).mean()\n",
    "sim2_ex = cos_sim(recon_ex, avg_hidden_vector).mean()\n",
    "sim3_ex = cos_sim(recon_ex, avg_recon_vector).mean()\n",
    "\n",
    "print(f\"Similiarity b/w reconstructed average and decoder bias vector: {round(sim1_ex.item(), 4)}\")\n",
    "print(f\"Similiarity b/w reconstructed average and average hidden activations: {round(sim2_ex.item(), 4)}\")\n",
    "print(f\"Similiarity b/w reconstructed average and average recon vector: {round(sim3_ex.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae49c6a0-80ac-4a14-a300-30a9271f7a82",
   "metadata": {},
   "source": [
    "Further example that our theory about the symmetry b/w 0 and N being off... the bias vector is not even close to any of the samples provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d15553-5c84-46d5-94ca-e6100f94f28e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
