{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84207c44-9c22-4853-943c-5a6cb08bdbdf",
   "metadata": {},
   "source": [
    "# Load Model For Genception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b67228-330c-480e-99b5-cb4001e89013",
   "metadata": {},
   "source": [
    "## SAE Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250d7778-885a-4a6d-9bd2-ddbcb9a27be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 256\n",
    "L1_PENALTY = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4a0ba-710d-4882-9bd0-f948e9f6fb9d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a4018f1-cb83-4f0b-90db-0f48aad1fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7038c3-06d1-4d3c-9b44-2f2bc3485f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_and_data.nn import NeuralNetwork\n",
    "from models_and_data.sae import SparseAutoencoder\n",
    "from models_and_data.edgedataset import EdgeDataset\n",
    "\n",
    "from models_and_data.model_helpers import (evaluate_and_gather_activations, get_sublabel_data, \n",
    "    get_top_N_features, extract_activations, load_intermediate_labels, seed_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbef66c-0819-4e4f-9fb7-346b8b786a6b",
   "metadata": {},
   "source": [
    "## Set Device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f93931-772a-4720-b394-0cff7884a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will be using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"We will be using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b553d6d-7e3a-4973-a472-3c735df1b699",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070db857-3892-4a37-b24a-b3f8a8d7bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_images = load_intermediate_labels(\"./intermediate-labels/first_layer/train_images.pkl\")\n",
    "train_labels = load_intermediate_labels(\"./intermediate-labels/first_layer/train_labels.pkl\")\n",
    "\n",
    "# val data\n",
    "val_images = load_intermediate_labels(\"./intermediate-labels/first_layer/val_images.pkl\")\n",
    "val_labels = load_intermediate_labels(\"./intermediate-labels/first_layer/val_labels.pkl\")\n",
    "\n",
    "# test data\n",
    "test_images = load_intermediate_labels(\"./intermediate-labels/first_layer/test_images.pkl\")\n",
    "test_labels = load_intermediate_labels(\"./intermediate-labels/first_layer/test_labels.pkl\")\n",
    "\n",
    "# intermediate labels\n",
    "N = 25\n",
    "sparse_type = \"top\"  # mask or top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59db04c-2352-435f-8b78-df59a7533489",
   "metadata": {},
   "source": [
    "# Genception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23752356-6fba-456a-bab9-94901a6aa0f7",
   "metadata": {},
   "source": [
    "## Model Result Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffaa23b1-17ba-4dad-9832-0ddb1bcb550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "if device.type.lower() == \"cpu\":\n",
    "    NUM_WORKERS = 0\n",
    "\n",
    "# training data\n",
    "train_dataset = EdgeDataset(train_images, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                          worker_init_fn=seed_worker, generator=generator, pin_memory=True)\n",
    "\n",
    "# validation data\n",
    "val_dataset = EdgeDataset(val_images, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)  # larger batch size for faster validation\n",
    "\n",
    "# test data\n",
    "test_dataset = EdgeDataset(test_images, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5514d7d2-8165-411a-8e1d-a6dcb6883dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "sae_hidden_one = SparseAutoencoder(input_size=16, hidden_size=HIDDEN_SIZE).to(device)\n",
    "sae_hidden_two = SparseAutoencoder(input_size=16, hidden_size=HIDDEN_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a44cea1-a15c-441d-b3ed-796353156bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path = \"./intermediate-labels-new/first_layer_results/F0/models/256_top/best_model_lf_0.23.pth\"\n",
    "# best_model_path = \"./intermediate-labels-new/first_layer_results/F0/models/25_top/best_model_lf_0.02.pth\"\n",
    "\n",
    "# best_model_path = \"./intermediate-labels-new/first_layer_results/classifier_results.pth\"\n",
    "\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "sae_hidden_one.load_state_dict(checkpoint['sae_one_state_dict'])\n",
    "sae_hidden_two.load_state_dict(checkpoint['sae_two_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bde98ef3-1f04-4809-bb0c-75ddfe4da04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model acc: 93.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_results = evaluate_and_gather_activations(model, sae_hidden_one, sae_hidden_two, train_loader, device)\n",
    "Z_train_one, Z_train_two, y_train = train_results[\"Z_one\"], train_results[\"Z_two\"], train_results[\"y\"]\n",
    "\n",
    "test_results = evaluate_and_gather_activations(model, sae_hidden_one, sae_hidden_two, test_loader, device)\n",
    "Z_test_one, Z_test_two, y_test = test_results[\"Z_one\"], test_results[\"Z_two\"], test_results[\"y\"]\n",
    "\n",
    "print(f\"Model acc: {test_results['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b603fa7-25d0-4cd0-955a-9bda271dff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Non-Zero Features per Image (Hidden One): 137.46\n",
      "Average Non-Zero Features per Image (Hidden Two): 140.25\n"
     ]
    }
   ],
   "source": [
    "sparsity_one = np.mean(Z_test_one > 1e-5) * Z_test_one.shape[1]\n",
    "sparsity_two = np.mean(Z_test_two > 1e-5) * Z_test_two.shape[1]\n",
    "print(f\"Average Non-Zero Features per Image (Hidden One): {sparsity_one:.2f}\")\n",
    "print(f\"Average Non-Zero Features per Image (Hidden Two): {sparsity_two:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77538fc-5162-441b-a219-bb1d826f4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Linear Probes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Probe Accuracy (Hidden One): 93.82%\n",
      "Linear Probe Accuracy (Hidden Two): 93.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Training Linear Probes ---\")\n",
    "clf_one = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "clf_one.fit(Z_train_one, y_train)\n",
    "acc_one = clf_one.score(Z_test_one, y_test)\n",
    "print(f\"Linear Probe Accuracy (Hidden One): {acc_one:.2%}\")\n",
    "\n",
    "clf_two = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "clf_two.fit(Z_train_two, y_train)\n",
    "acc_two = clf_two.score(Z_test_two, y_test)\n",
    "print(f\"Linear Probe Accuracy (Hidden Two): {acc_two:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37e8bb-2c43-403d-8756-2f0bc1024a56",
   "metadata": {},
   "source": [
    "## Target Reconstruction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bd15a98-9765-45c9-b4ad-47c4cdb2d9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Activations: 100%|████████████████████████████████████████████████████████| 782/782 [00:01<00:00, 625.95it/s]\n"
     ]
    }
   ],
   "source": [
    "activation_data = extract_activations(\n",
    "    data_loader=train_loader,\n",
    "    model=model,\n",
    "    sae_one=sae_hidden_one,\n",
    "    sae_two=sae_hidden_two,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d65a9cc-deba-495b-828e-269498b537ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used:\n",
      "25\n",
      "Size of datasets:\n",
      "50000 10000 10000 50000\n",
      "Features used:\n",
      "256\n",
      "Size of datasets:\n",
      "50000 10000 10000 50000\n"
     ]
    }
   ],
   "source": [
    "sparse_vector_sizes = [25, 256]\n",
    "for N_recon in sparse_vector_sizes:\n",
    "    labels = activation_data[\"labels\"]\n",
    "    sparse_act_one = activation_data[\"sparse_one\"]\n",
    "    avg_digit_encoding, top_n_features = get_top_N_features(N_recon, sparse_act_one, labels)\n",
    "    \n",
    "    feature_indices_dict = {}\n",
    "    for digit in range(0, 10):\n",
    "        feature_indices_dict[digit] = top_n_features[digit]['indices']\n",
    "    \n",
    "    print(\"Features used:\")\n",
    "    print(len(feature_indices_dict[0]))\n",
    "    \n",
    "    recon_max_sparse_training, recon_max_sparse_ablated_training = get_sublabel_data(train_labels,\n",
    "                                                                                     train_images,\n",
    "                                                                                     feature_indices_dict,\n",
    "                                                                                     sparse_act_one,\n",
    "                                                                                     sae_hidden_one,\n",
    "                                                                                     device,\n",
    "                                                                                     HIDDEN_SIZE\n",
    "                                                                                    )\n",
    "    \n",
    "    print(\"Size of datasets:\")\n",
    "    print(len(train_images), len(val_images), len(test_images), len(recon_max_sparse_training))\n",
    "    \n",
    "    file_path = f\"./{N_recon}_top.pkl\"\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(recon_max_sparse_training, f)\n",
    "    \n",
    "    file_path = f\"./{N_recon}_mask.pkl\"\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(recon_max_sparse_ablated_training, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b96637-4722-4e22-914b-cb9d9a8f09d2",
   "metadata": {},
   "source": [
    "# Some Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c530554-d781-40c4-bd99-f4d69e531425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity b/w hidden activations and decoder bias vector: -0.2551\n",
      "Similarity b/w hidden activations and reconstructed activations: 1.0\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.from_numpy(np.mean(activation_data['hidden_one'], axis=0)).float()\n",
    "tensor2 = sae_hidden_one.decoder.bias.cpu()\n",
    "\n",
    "cos_sim = nn.CosineSimilarity(dim=0)\n",
    "t1t2_sim = cos_sim(tensor1, tensor2).mean()\n",
    "\n",
    "tensor3 = torch.from_numpy(np.mean(activation_data['recon_one'], axis=0)).float()\n",
    "t1t3_sim = cos_sim(tensor1, tensor3).mean()\n",
    "\n",
    "print(f\"Similarity b/w hidden activations and decoder bias vector: {round(t1t2_sim.item(), 4)}\")\n",
    "print(f\"Similarity b/w hidden activations and reconstructed activations: {round(t1t3_sim.item(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d324aaf-0213-4110-9176-72e302d99b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_one_w = sae_hidden_one.decoder.weight.cpu()\n",
    "sae_one_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88d6c9-d24e-4c27-90e2-f660d33e5f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
