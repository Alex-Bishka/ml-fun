{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84207c44-9c22-4853-943c-5a6cb08bdbdf",
   "metadata": {},
   "source": [
    "# Loop to for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa37d0-59c1-4368-aec0-83ccb0ce6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EXPERIMENT_TYPE = \"SAE\"\n",
    "RUN_ID = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b67228-330c-480e-99b5-cb4001e89013",
   "metadata": {},
   "source": [
    "## SAE Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d7778-885a-4a6d-9bd2-ddbcb9a27be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 256\n",
    "L1_PENALTY = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4a0ba-710d-4882-9bd0-f948e9f6fb9d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4018f1-cb83-4f0b-90db-0f48aad1fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7038c3-06d1-4d3c-9b44-2f2bc3485f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_helpers import (plot_weights,\n",
    "                    plot_activations,\n",
    "                    plot_losses,\n",
    "                    plot_saliency_map,\n",
    "                    plot_sparse_vecs_by_image,\n",
    "                    plot_top_act_images_by_feature,\n",
    "                    feature_inversion,\n",
    "                    load_intermediate_labels\n",
    "                )\n",
    "\n",
    "from model_helpers import evaluate_and_gather_activations, get_sublabel_data, get_top_N_features, extract_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c069cc3-458e-4825-9828-c771c7f7370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# assume cwd is project_root/data_loader\n",
    "project_root = Path(os.getcwd()).parent  # go up one level to project_root\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from helpers import load_images, load_labels, visualize_image, get_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbef66c-0819-4e4f-9fb7-346b8b786a6b",
   "metadata": {},
   "source": [
    "## Set Device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f93931-772a-4720-b394-0cff7884a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"We will be using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b553d6d-7e3a-4973-a472-3c735df1b699",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070db857-3892-4a37-b24a-b3f8a8d7bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_images = load_intermediate_labels(\"./intermediate-labels/first_layer/train_images.pkl\")\n",
    "train_labels = load_intermediate_labels(\"./intermediate-labels/first_layer/train_labels.pkl\")\n",
    "\n",
    "# val data\n",
    "val_images = load_intermediate_labels(\"./intermediate-labels/first_layer/val_images.pkl\")\n",
    "val_labels = load_intermediate_labels(\"./intermediate-labels/first_layer/val_labels.pkl\")\n",
    "\n",
    "# test data\n",
    "test_images = load_intermediate_labels(\"./intermediate-labels/first_layer/test_images.pkl\")\n",
    "test_labels = load_intermediate_labels(\"./intermediate-labels/first_layer/test_labels.pkl\")\n",
    "\n",
    "# intermediate labels\n",
    "N = 25\n",
    "sparse_type = \"top\"  # mask or top\n",
    "\n",
    "recon_max_sparse_act_one = load_intermediate_labels(f\"./intermediate-labels-new/first_layer/F0/{N}_{sparse_type}.pkl\")\n",
    "# recon_max_sparse_act_one = load_intermediate_labels(f\"./intermediate-labels-new/first_layer/F1/0.04/{N}_{sparse_type}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de73dd-39e5-4c74-b3a3-03b6155d3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(recon_max_sparse_act_one[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e03f6-1174-4b0a-bac4-a30b30deff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Val images shape:\", val_images.shape)\n",
    "print(\"Test images shape:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca05d5-d791-4fbb-9736-b52a5eae1409",
   "metadata": {},
   "source": [
    "## Visualize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6f14c-5f30-4237-933c-55a6f254a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = train_images[0]\n",
    "sample_label = train_labels[0]\n",
    "visualize_image(sample_image, sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d7fd35-fd62-4598-89f5-58f98567ad3c",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "### NN\n",
    "\n",
    "Once again, two hidden layers. 16 nodes each. Same as 3blue1brown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d2535-98f4-4c1e-8073-c5373a5b56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layer_size_by_pixels = 28*28\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # define layers separately to have access to each\n",
    "        self.hidden_one = nn.Linear(layer_size_by_pixels, 16)\n",
    "        self.hidden_two = nn.Linear(16, 16)\n",
    "        self.classification_layer = nn.Linear(16, 10)\n",
    "        \n",
    "        self.activation_function = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # first hidden layer\n",
    "        hidden_one_out = self.hidden_one(x)\n",
    "        hidden_one_act = self.activation_function(hidden_one_out)\n",
    "\n",
    "        # second hidden layer\n",
    "        hidden_two_out = self.hidden_two(hidden_one_act)\n",
    "        hidden_two_act = self.activation_function(hidden_two_out)\n",
    "\n",
    "        # classification layer\n",
    "        classification_out = self.classification_layer(hidden_two_act)\n",
    "        \n",
    "        return classification_out, hidden_one_act, hidden_two_act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44c3cf-602d-451e-b10c-8b7f005858e8",
   "metadata": {},
   "source": [
    "### SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53786553-7c2c-4d0f-96a9-b901297c7756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size=16, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, input_size)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.activation(self.encoder(x))\n",
    "        reconstructed = self.decoder(encoded)\n",
    "        return reconstructed, encoded\n",
    "    \n",
    "    def loss(self, x, reconstructed, encoded, l1_lambda=0.001):\n",
    "        mse_loss = nn.MSELoss()(reconstructed, x)\n",
    "        l1_loss = l1_lambda * torch.mean(torch.abs(encoded))\n",
    "        return mse_loss + l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa3f1a-32f7-46d9-975d-3c7c77d95a9f",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0386b-042b-4e96-8266-adb647758c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDataset(Dataset):\n",
    "    def __init__(self, images, labels, first_layer_acts=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.first_layer_acts = first_layer_acts\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.images) == len(self.labels)\n",
    "        if self.first_layer_acts:\n",
    "            assert(len(self.first_layer_acts) == len(self.images))\n",
    "            \n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.from_numpy(self.images[idx].copy()).float()\n",
    "        label = torch.tensor(self.labels[idx].copy(), dtype=torch.long)\n",
    "\n",
    "        if self.first_layer_acts:\n",
    "            return (image, label, self.first_layer_acts[idx])\n",
    "        else:\n",
    "            return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f8215-1f78-4e3f-975f-1bddf935cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility on training\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b878bdc7-4dc6-4510-a3a7-d64a2d2d7394",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d0ec92-fd07-4789-84ec-c9d426588e63",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54e2f0-e0d4-4a9d-8b53-bac191c5cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 0.01\n",
    "max_loss = 0.30\n",
    "step = 0.01\n",
    "loss_factors = np.arange(min_loss, round(max_loss + step, 3), step)\n",
    "print(len(loss_factors))\n",
    "print(loss_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb01e5-8b29-41a8-b822-b5884205d2f8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efead09-bdd4-4177-9ead-fee16bb28a15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_data_dict = {}\n",
    "for loss_factor in loss_factors:\n",
    "    print(\"#\" * 50)\n",
    "    print(f\"Loss factor: {loss_factor}\\n\\n\")\n",
    "    ######################################################################################################\n",
    "    # MODELS INIT\n",
    "    ######################################################################################################\n",
    "    \n",
    "    # for reproducibility\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    model = NeuralNetwork().to(device)\n",
    "\n",
    "    # for reproducibility\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    sae_hidden_one = SparseAutoencoder(input_size=16, hidden_size=HIDDEN_SIZE).to(device)\n",
    "\n",
    "    # for reproducibility\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    sae_hidden_two = SparseAutoencoder(input_size=16, hidden_size=HIDDEN_SIZE).to(device)\n",
    "\n",
    "    # print(f\"SAE weights: {sae_hidden_one.encoder.weight[0][:5].detach().cpu().numpy()}\")\n",
    "    # print(f\"SAE weights: {sae_hidden_two.encoder.weight[0][:5].detach().cpu().numpy()}\")\n",
    "\n",
    "    classification_loss_fn = nn.CrossEntropyLoss()\n",
    "    hidden_act_one_loss_fn = nn.CosineSimilarity()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    optimizer_sae_hidden_one = torch.optim.Adam(sae_hidden_one.parameters())\n",
    "    optimizer_sae_hidden_two = torch.optim.Adam(sae_hidden_two.parameters())\n",
    "        \n",
    "    \n",
    "    ######################################################################################################\n",
    "    # DATA INIT\n",
    "    ######################################################################################################\n",
    "    seed = 42\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    \n",
    "    NUM_WORKERS = 4\n",
    "    if device.type.lower() == \"cpu\":\n",
    "        NUM_WORKERS = 0\n",
    "    \n",
    "    # training data\n",
    "    train_dataset = EdgeDataset(train_images, train_labels, recon_max_sparse_act_one)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                              worker_init_fn=seed_worker, generator=generator, pin_memory=True)\n",
    "    \n",
    "    # validation data\n",
    "    val_dataset = EdgeDataset(val_images, val_labels)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)  # larger batch size for faster validation\n",
    "    \n",
    "    # test data\n",
    "    test_dataset = EdgeDataset(test_images, test_labels)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    ######################################################################################################\n",
    "    # TRAINING LOOP\n",
    "    ######################################################################################################\n",
    "    num_epochs = 20    \n",
    "    best_val_acc = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training Phase ---\n",
    "        model.train()  # set the model to training mode - this is currently a no-op\n",
    "        sae_hidden_two.train()\n",
    "        sae_hidden_one.train()\n",
    "        \n",
    "        train_loss, sae_loss_one, sae_loss_two = 0.0, 0.0, 0.0\n",
    "    \n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Train]\", leave=False)\n",
    "        for batch_idx, batch in enumerate(train_bar):\n",
    "            # deconstruct batch items\n",
    "            images, labels, acts_one = batch\n",
    "            images, labels, acts_one = images.to(device), labels.to(device), acts_one.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            optimizer.zero_grad()\n",
    "            classification_out, hidden_act_one, hidden_act_two = model(images)            \n",
    "            sub_loss = (1 - hidden_act_one_loss_fn(hidden_act_one, acts_one)).mean()\n",
    "            total_loss = classification_loss_fn(classification_out, labels) + loss_factor * (sub_loss)\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += total_loss.item()\n",
    "            train_bar.set_postfix(loss=total_loss.item())\n",
    "    \n",
    "            # to prevent backprop on both graphs:\n",
    "            hidden_act_one_detached = hidden_act_one.detach()\n",
    "            hidden_act_two_detached = hidden_act_two.detach()\n",
    "    \n",
    "            # SAE loss and backprop - hidden layer one\n",
    "            optimizer_sae_hidden_one.zero_grad()\n",
    "            reconstructed_one, encoded_one = sae_hidden_one(hidden_act_one_detached)\n",
    "            loss1 = sae_hidden_one.loss(hidden_act_one_detached,\n",
    "                                                      reconstructed_one,\n",
    "                                                      encoded_one,\n",
    "                                                      l1_lambda=L1_PENALTY\n",
    "                                                     )\n",
    "            loss1.backward()\n",
    "            optimizer_sae_hidden_one.step()\n",
    "            sae_loss_one += loss1.item()\n",
    "            \n",
    "            # SAE loss and backprop - hidden layer two\n",
    "            optimizer_sae_hidden_two.zero_grad()\n",
    "            reconstructed_two, encoded_two = sae_hidden_two(hidden_act_two_detached)\n",
    "            loss2 = sae_hidden_two.loss(hidden_act_two_detached,\n",
    "                                                      reconstructed_two,\n",
    "                                                      encoded_two,\n",
    "                                                      l1_lambda=L1_PENALTY\n",
    "                                                     )\n",
    "            loss2.backward()\n",
    "            optimizer_sae_hidden_two.step()\n",
    "            sae_loss_two += loss2.item()\n",
    "    \n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                # deconstruct\n",
    "                images, labels = batch\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "                classification_out, _, _ = model(images)\n",
    "                loss = classification_loss_fn(classification_out, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(classification_out, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "    \n",
    "        # epoch stats\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct / total\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")\n",
    "    \n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_val_acc = val_accuracy\n",
    "            \n",
    "            model_path = f'./models/best_model_lf_{round(loss_factor, 3)}.pth'\n",
    "            os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "            # Save all three model states in one file\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'sae_one_state_dict': sae_hidden_one.state_dict(),\n",
    "                'sae_two_state_dict': sae_hidden_two.state_dict(),\n",
    "            }, model_path)\n",
    "            best_model_path = model_path\n",
    "            print(f\"  -> Saved best model checkpoint to {best_model_path}\")\n",
    "    \n",
    "    \n",
    "    ######################################################################################################\n",
    "    # EVAL\n",
    "    ######################################################################################################\n",
    "    if best_model_path is None:\n",
    "        print(\"No best model was saved. Skipping evaluation.\")\n",
    "        continue\n",
    "        \n",
    "    # Load the best models from the saved checkpoint\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    sae_hidden_one.load_state_dict(checkpoint['sae_one_state_dict'])\n",
    "    sae_hidden_two.load_state_dict(checkpoint['sae_two_state_dict'])\n",
    "\n",
    "    # This ensures the data order is reset and will match any future manual evaluation.\n",
    "    print(\"\\nRe-initializing DataLoaders for consistent evaluation...\")\n",
    "    seed = 42\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                              worker_init_fn=seed_worker, generator=generator, pin_memory=True)\n",
    "    # test_loader doesn't need re-init since shuffle=False, but it's good practice for clarity.\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    # --- Get Test Metrics and Activations in ONE PASS ---\n",
    "    test_results = evaluate_and_gather_activations(model, sae_hidden_one, sae_hidden_two, test_loader, device)\n",
    "    Z_test_one, Z_test_two, y_test = test_results[\"Z_one\"], test_results[\"Z_two\"], test_results[\"y\"]\n",
    "    print(f\"\\nFinal Test Accuracy: {test_results['accuracy']:.2f}%\")\n",
    "    print(f\"Average Reconstruction Error (Hidden One): {test_results['recon_error_one']:.4f}\")\n",
    "    print(f\"Average Reconstruction Error (Hidden Two): {test_results['recon_error_two']:.4f}\")\n",
    "    \n",
    "    # Compute sparsity (average non-zero features per image)\n",
    "    sparsity_one = np.mean(Z_test_one > 1e-5) * Z_test_one.shape[1]\n",
    "    sparsity_two = np.mean(Z_test_two > 1e-5) * Z_test_two.shape[1]\n",
    "    print(f\"Average Non-Zero Features per Image (Hidden One): {sparsity_one:.2f}\")\n",
    "    print(f\"Average Non-Zero Features per Image (Hidden Two): {sparsity_two:.2f}\")\n",
    "\n",
    "    # --- Get Training Activations for Probes in ONE PASS ---\n",
    "    # We only need Z_one, Z_two, and y, so we can ignore the other returned values\n",
    "    print(\"\\nGathering activations from training set for probing...\")\n",
    "    train_results = evaluate_and_gather_activations(model, sae_hidden_one, sae_hidden_two, train_loader, device)\n",
    "    Z_train_one, Z_train_two, y_train = train_results[\"Z_one\"], train_results[\"Z_two\"], train_results[\"y\"]\n",
    "    \n",
    "    ######################################################################################################\n",
    "    # SPARSE FEATURE PROBES\n",
    "    ######################################################################################################\n",
    "    print(\"\\n--- Training Linear Probes ---\")\n",
    "    clf_one = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "    clf_one.fit(Z_train_one, y_train)\n",
    "    acc_one = clf_one.score(Z_test_one, y_test)\n",
    "    print(f\"Linear Probe Accuracy (Hidden One): {acc_one:.2%}\")\n",
    "    \n",
    "    clf_two = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "    clf_two.fit(Z_train_two, y_train)\n",
    "    acc_two = clf_two.score(Z_test_two, y_test)\n",
    "    print(f\"Linear Probe Accuracy (Hidden Two): {acc_two:.2%}\")\n",
    "\n",
    "    # --- Log final results ---\n",
    "    loss_data_dict[loss_factor] = {\n",
    "        \"Final_Accuracy\": test_results['accuracy'],\n",
    "        \"S1_Probe_Acccuracy\": acc_one,\n",
    "        \"S2_Probe_Acccuracy\": acc_two,\n",
    "    }\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    del model, sae_hidden_one, sae_hidden_two, checkpoint\n",
    "    del Z_train_one, Z_train_two, y_train, Z_test_one, Z_test_two, y_test\n",
    "    del train_results, test_results, clf_one, clf_two\n",
    "    torch.cuda.empty_cache()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce1426-747d-470a-a42a-d5b13b3c776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd96fe2-4d73-41b2-8d57-556ba65e9e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_acc = 0\n",
    "max_digit = -1\n",
    "for digit in loss_data_dict.keys():\n",
    "    if loss_data_dict[digit][\"Final_Accuracy\"] > max_acc:\n",
    "        max_acc = loss_data_dict[digit][\"Final_Accuracy\"]\n",
    "        max_digit = digit\n",
    "\n",
    "print(max_digit)\n",
    "print(loss_data_dict[max_digit][\"Final_Accuracy\"])\n",
    "print(loss_data_dict[max_digit][\"S1_Probe_Acccuracy\"])\n",
    "print(loss_data_dict[max_digit][\"S2_Probe_Acccuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010961c7-3829-472c-aa25-214f72da0cc1",
   "metadata": {},
   "source": [
    "## Saving Loss Factor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ba107-3ab6-473f-b610-5283e28e633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"./loss_data_dict_{min_loss}_to_{round(loss_factors[-1], 3)}_{N}_{sparse_type}.pkl\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(loss_data_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59db04c-2352-435f-8b78-df59a7533489",
   "metadata": {},
   "source": [
    "# Genception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f07f612-1268-4cce-a5f3-1a61e891f4dc",
   "metadata": {},
   "source": [
    "## Model Result Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514d7d2-8165-411a-8e1d-a6dcb6883dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "sae_hidden_one = SparseAutoencoder(input_size=16, hidden_size=HIDDEN_SIZE).to(device)\n",
    "sae_hidden_two = SparseAutoencoder(input_size=16, hidden_size=HIDDEN_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44cea1-a15c-441d-b3ed-796353156bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"./best_model_lf_0.pth\"\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "sae_hidden_one.load_state_dict(checkpoint['sae_one_state_dict'])\n",
    "sae_hidden_two.load_state_dict(checkpoint['sae_two_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592fa80-4613-433c-ba23-63ac0ae97efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "if device.type.lower() == \"cpu\":\n",
    "    NUM_WORKERS = 0\n",
    "\n",
    "# training data\n",
    "train_dataset = EdgeDataset(train_images, train_labels, recon_max_sparse_act_one)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=NUM_WORKERS,\n",
    "                          worker_init_fn=seed_worker, generator=generator, pin_memory=True)\n",
    "\n",
    "# validation data\n",
    "val_dataset = EdgeDataset(val_images, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)  # larger batch size for faster validation\n",
    "\n",
    "# test data\n",
    "test_dataset = EdgeDataset(test_images, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a325cc-3778-4ff8-a494-f3526297c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = evaluate_and_gather_activations(model, sae_hidden_one, sae_hidden_two, train_loader, device)\n",
    "Z_train_one, Z_train_two, y_train = train_results[\"Z_one\"], train_results[\"Z_two\"], train_results[\"y\"]\n",
    "\n",
    "test_results = evaluate_and_gather_activations(model, sae_hidden_one, sae_hidden_two, test_loader, device)\n",
    "Z_test_one, Z_test_two, y_test = test_results[\"Z_one\"], test_results[\"Z_two\"], test_results[\"y\"]\n",
    "\n",
    "print(f\"Model acc: {test_results['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c98f1e5-af8d-4167-8aa3-f1cfa8da80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Training Linear Probes ---\")\n",
    "clf_one = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "clf_one.fit(Z_train_one, y_train)\n",
    "acc_one = clf_one.score(Z_test_one, y_test)\n",
    "print(f\"Linear Probe Accuracy (Hidden One): {acc_one:.2%}\")\n",
    "\n",
    "clf_two = LogisticRegression(penalty='l2', max_iter=1000, n_jobs=-1)\n",
    "clf_two.fit(Z_train_two, y_train)\n",
    "acc_two = clf_two.score(Z_test_two, y_test)\n",
    "print(f\"Linear Probe Accuracy (Hidden Two): {acc_two:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529af3a6-87d5-49f1-9914-16445482edab",
   "metadata": {},
   "source": [
    "## Target Reconstruction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd15a98-9765-45c9-b4ad-47c4cdb2d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_data = extract_activations(\n",
    "    data_loader=train_loader,\n",
    "    model=model,\n",
    "    sae_one=sae_hidden_one,\n",
    "    sae_two=sae_hidden_two,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de4673-3296-44a6-bd67-c756d10a03ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vector_sizes = [25, 256]\n",
    "for N_recon in sparse_vector_sizes:\n",
    "    labels = activation_data[\"labels\"]\n",
    "    sparse_act_one = activation_data[\"sparse_one\"]\n",
    "    avg_digit_encoding, top_n_features = get_top_N_features(N_recon, sparse_act_one, labels)\n",
    "    \n",
    "    feature_indices_dict = {}\n",
    "    for digit in range(0, 10):\n",
    "        feature_indices_dict[digit] = top_n_features[digit]['indices']\n",
    "    \n",
    "    print(\"Features used:\")\n",
    "    print(len(feature_indices_dict[0]))\n",
    "    \n",
    "    recon_max_sparse_training, recon_max_sparse_ablated_training = get_sublabel_data(train_labels,\n",
    "                                                                                     train_images,\n",
    "                                                                                     feature_indices_dict,\n",
    "                                                                                     sparse_act_one,\n",
    "                                                                                     sae_hidden_one,\n",
    "                                                                                     device,\n",
    "                                                                                     HIDDEN_SIZE\n",
    "                                                                                    )\n",
    "    \n",
    "    print(\"Size of datasets:\")\n",
    "    print(len(train_images), len(val_images), len(test_images), len(recon_max_sparse_training))\n",
    "    \n",
    "    file_path = f\"./{N_recon}_top.pkl\"\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(recon_max_sparse_training, f)\n",
    "    \n",
    "    file_path = f\"./{N_recon}_mask.pkl\"\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(recon_max_sparse_ablated_training, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
