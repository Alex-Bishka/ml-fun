{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84207c44-9c22-4853-943c-5a6cb08bdbdf",
   "metadata": {},
   "source": [
    "# MNIST Partial Questing - with Curves! For longer!\n",
    "\n",
    "Increasing training time for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf4a0ba-710d-4882-9bd0-f948e9f6fb9d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4018f1-cb83-4f0b-90db-0f48aad1fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers import load_images, load_labels, visualize_image, get_edges, generate_intermediate_edge_labels, horizontal_kernel, vertical_kernel, \\\n",
    "    load_intermediate_labels, generate_intermediate_curve_labels, save_intermediate_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0deb78-256b-4707-91a7-edc188218dda",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd96ee9-64c6-495c-8ea1-930290f954be",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"./curve_partial_long.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbef66c-0819-4e4f-9fb7-346b8b786a6b",
   "metadata": {},
   "source": [
    "## Set Device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f93931-772a-4720-b394-0cff7884a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"We will be using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b553d6d-7e3a-4973-a472-3c735df1b699",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070db857-3892-4a37-b24a-b3f8a8d7bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "train_images = load_images(\"./data/train-images-idx3-ubyte/train-images-idx3-ubyte\")\n",
    "train_labels = load_labels(\"./data/train-labels-idx1-ubyte/train-labels-idx1-ubyte\")\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels,\n",
    "    test_size=1/6,  # 10k validation\n",
    "    stratify=train_labels,\n",
    "    random_state=42  # for reproducibility\n",
    ")\n",
    "\n",
    "# test data\n",
    "test_images = load_images(\"./data/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\")\n",
    "test_labels = load_labels(\"./data/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e03f6-1174-4b0a-bac4-a30b30deff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Val images shape:\", val_images.shape)\n",
    "print(\"Test images shape:\", test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270894df-0fa4-4d4b-ae75-8e90ce07e8ac",
   "metadata": {},
   "source": [
    "## Visualize an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b573b5-763a-42bb-b3dd-a8160357194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = train_images[0]\n",
    "sample_label = train_labels[0]\n",
    "visualize_image(sample_image, sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05623254-d358-4eeb-a535-dda1b17ffcc6",
   "metadata": {},
   "source": [
    "## Convolutions to get Horizontal Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e926333-e915-4f3b-b0bb-60c61233e346",
   "metadata": {},
   "source": [
    "### Example Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113ba4a-1a57-4bdf-a32b-25e2018e1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_edges = get_edges(horizontal_kernel, sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5120d1-8b77-43f8-924b-0de360a8ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(horizontal_edges, f\"{sample_label} horizontal edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e610f8-ea28-41cd-8d8a-6fb8878e29b1",
   "metadata": {},
   "source": [
    "### Extending the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe6896-5ce3-45de-b4f4-4a837a5bb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horizontal_image_labels = load_intermediate_labels(\"train_horizontal_image_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f888ca-0507-4256-9deb-5377e7147f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_horizontal_image_labels = load_intermediate_labels(\"val_horizontal_image_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87afaea-31e9-4e75-85e2-bd963aaf59c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_horizontal_image_labels = load_intermediate_labels(\"test_horizontal_image_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b07c68-0b2f-40ed-92bd-5c0752f43da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(train_horizontal_image_labels[0].reshape(28, 28), \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1e874-dbd8-4306-891b-e4b543723dbc",
   "metadata": {},
   "source": [
    "## Convolutions to get Vertical Edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66748039-c750-43b5-8388-7c91f61224ea",
   "metadata": {},
   "source": [
    "### Example Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b7385e-91ba-4223-bbed-83b309a4578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_edges = get_edges(vertical_kernel, sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30570246-eed3-4f7a-8251-d06c418af8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(vertical_edges, f\"{sample_label} vertical edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820c65c-02ac-4bbb-b9cc-d22fc2f2673d",
   "metadata": {},
   "source": [
    "### Extending the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d0eaa-60cb-4e2b-a26c-21fada7d712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vertical_image_labels = load_intermediate_labels(\"train_vertical_image_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957d3563-aae4-464d-aded-bae41638e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_vertical_image_labels = load_intermediate_labels(\"val_vertical_image_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c68ad-3ee2-4755-ab60-324d554fdb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vertical_image_labels = load_intermediate_labels(\"test_vertical_image_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c116c99-a6bf-4c89-8290-e71eb673e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(train_vertical_image_labels[0].reshape(28, 28), \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f3878-0f82-4f83-8ffa-0ab928eb1a5c",
   "metadata": {},
   "source": [
    "## Convolutions to get Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c124f-7370-47a3-a86a-e85dc8c69959",
   "metadata": {},
   "source": [
    "Some extra steps here to generate better curves... this might be a point to re-visit in testing, but it largely comes from needing to rotate our curve kernel to capture curves.\n",
    "\n",
    "The point to revisit is perhaps we want each unique rotation to be represented by an intermediate layer. Similar to how edges have been split into vertical and horizontal layers, perhaps we want layers to be dedicated to only one curve, instead of the culmination of curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b0049-66a0-4d90-87fe-c14329e3777d",
   "metadata": {},
   "source": [
    "### Example Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea665831-a92b-4dc3-b456-13f346fc3942",
   "metadata": {},
   "outputs": [],
   "source": [
    "curves = generate_intermediate_curve_labels([sample_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b914623-6adc-4f07-957f-01de03bf997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(curves[0].reshape(28, 28), f\"{sample_label} curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437fc635-7c62-4275-86c2-3009822f8e2e",
   "metadata": {},
   "source": [
    "### Extending the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ad5f3-f242-4aa0-a91d-8c9deee06daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_curve_labels = load_intermediate_labels(\"train_curve_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca92b3-a9c1-455d-a01f-0f5a011e85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_curve_labels = load_intermediate_labels(\"val_curve_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc850be-60ea-4d22-8a1a-58b6a40d7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_curve_labels = load_intermediate_labels(\"test_curve_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2a364-bc05-4b56-a6c3-7443d430e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(train_curve_labels[0].reshape(28, 28), \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517abc1-b197-47cc-b71a-921b059ba56d",
   "metadata": {},
   "source": [
    "# Base Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d7fd35-fd62-4598-89f5-58f98567ad3c",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "Updating the architecture to take into account our new curve layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d2535-98f4-4c1e-8073-c5373a5b56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layer_size_by_pixels = 28*28\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # define layers separately to have access to each\n",
    "        self.horizontal_layer = nn.Linear(layer_size_by_pixels, layer_size_by_pixels)\n",
    "        self.vertical_layer = nn.Linear(layer_size_by_pixels, layer_size_by_pixels)\n",
    "        self.curve_layer = nn.Linear(layer_size_by_pixels, layer_size_by_pixels)\n",
    "        self.classification_layer = nn.Linear(layer_size_by_pixels, 10)\n",
    "        self.activation_function = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # horizontal processing\n",
    "        horizontal_out = self.horizontal_layer(x)\n",
    "        horizontal_act = self.activation_function(horizontal_out)\n",
    "\n",
    "        # vertical processing\n",
    "        vertical_out = self.vertical_layer(horizontal_act)\n",
    "        vertical_act = self.activation_function(vertical_out)\n",
    "\n",
    "        # curve processing\n",
    "        curve_out = self.curve_layer(vertical_act)\n",
    "        curve_act = self.activation_function(curve_out)\n",
    "\n",
    "        # classification\n",
    "        classification_out = self.classification_layer(curve_act)\n",
    "        \n",
    "        return classification_out, curve_act, vertical_act, horizontal_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ff754-354f-4345-b7a8-637e1cbbe83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9cc14-5e72-4f33-b2cc-cd356e881c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "# loss functions\n",
    "classification_loss_fn = nn.CrossEntropyLoss()\n",
    "horizontal_loss_fn = nn.MSELoss()\n",
    "vertical_loss_fn = nn.MSELoss()\n",
    "curve_loss_fn = nn.MSELoss()\n",
    "\n",
    "# optimizers\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e8694-36ec-4f8b-b78d-f63acdc38dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model weights (to compare below): {model.horizontal_layer.weight[0][:5].detach().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d245a92-a504-453b-96b3-6c0827fcb344",
   "metadata": {},
   "source": [
    "### Verify Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e28ddd-9831-421e-b1d1-767c0f837e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "model_compare_one = NeuralNetwork().to(device)\n",
    "first_set_of_weights = model_compare_one.horizontal_layer.weight[0][:5].detach().cpu().numpy()\n",
    "print(\"First set of weights:\", first_set_of_weights)\n",
    "\n",
    "# reset the seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "model_compare_two = NeuralNetwork().to(device)\n",
    "second_set_of_weights = model_compare_two.horizontal_layer.weight[0][:5].detach().cpu().numpy()\n",
    "print(\"Second set of weights:\", second_set_of_weights)\n",
    "\n",
    "print(f\"Are the two sets equal: {first_set_of_weights == second_set_of_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa3f1a-32f7-46d9-975d-3c7c77d95a9f",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0386b-042b-4e96-8266-adb647758c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDataset(Dataset):\n",
    "    def __init__(self, images, labels, horizontal_edges, vertical_edges, curves):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.horizontal_edges = horizontal_edges\n",
    "        self.vertical_edges = vertical_edges\n",
    "        self.curves = curves\n",
    "\n",
    "    def __len__(self):\n",
    "        assert len(self.images) == len(self.labels)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.from_numpy(self.images[idx].copy()).float(),\n",
    "            torch.tensor(self.labels[idx].copy(), dtype=torch.long),\n",
    "            torch.from_numpy(self.horizontal_edges[idx].copy()).float(),\n",
    "            torch.from_numpy(self.vertical_edges[idx].copy()).float(),\n",
    "            torch.from_numpy(self.curves[idx].copy()).float(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f8215-1f78-4e3f-975f-1bddf935cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility on training\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "generator = torch.Generator().manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c300da9-178d-46a0-ba00-cf68f0e7cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train_dataset = EdgeDataset(train_images, train_labels, train_horizontal_image_labels, train_vertical_image_labels, train_curve_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, worker_init_fn=seed_worker, generator=generator)\n",
    "\n",
    "# validation data\n",
    "val_dataset = EdgeDataset(val_images, val_labels, val_horizontal_image_labels, val_vertical_image_labels, val_curve_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)  # larger batch size for faster validation\n",
    "\n",
    "# test data\n",
    "test_dataset = EdgeDataset(test_images, test_labels, test_horizontal_image_labels, test_vertical_image_labels, test_curve_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b878bdc7-4dc6-4510-a3a7-d64a2d2d7394",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb196da6-5484-413e-a599-139ab416b7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 150\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training Phase ---\n",
    "    model.train()  # set the model to training mode - this is currently a no-op\n",
    "    train_loss = 0.0\n",
    "\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Train]\", leave=False)\n",
    "    for batch in train_bar:\n",
    "        # deconstruct batch items\n",
    "        images, labels, horizontal_labels, vertical_labels, curve_labels = batch\n",
    "        images, labels, horizontal_labels, vertical_labels, curve_labels = images.to(device), \\\n",
    "            labels.to(device), \\\n",
    "            horizontal_labels.to(device), \\\n",
    "            vertical_labels.to(device), \\\n",
    "            curve_labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        classification_out, curve_act, vertical_act, horizontal_act = model(images)\n",
    "        \n",
    "        # --- Loss and Backprop ---\n",
    "\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # curve_loss \n",
    "        curve_loss = curve_loss_fn(curve_act, curve_labels)\n",
    "        \n",
    "        # vertical loss\n",
    "        vertical_loss = vertical_loss_fn(vertical_act, vertical_labels)\n",
    "\n",
    "        # horizontal loss\n",
    "        horizontal_loss = horizontal_loss_fn(horizontal_act, horizontal_labels)\n",
    "\n",
    "        # classification loss\n",
    "        classification_loss = classification_loss_fn(classification_out, labels)\n",
    "\n",
    "        # total loss\n",
    "        total_loss = curve_loss + vertical_loss + horizontal_loss + classification_loss\n",
    "        total_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # update progress\n",
    "        train_loss += total_loss.item()\n",
    "        train_bar.set_postfix(loss=classification_loss.item())\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Val]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in val_bar:\n",
    "            # deconstruct\n",
    "            images, labels, _, _, _ = batch\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            classification_out, _, _, _ = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = classification_loss_fn(classification_out, labels)\n",
    "\n",
    "            # calculate metrics\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(classification_out, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # epoch stats\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2baa9-2c67-4e58-b9e2-fb3cfa9f374d",
   "metadata": {},
   "source": [
    "So our training doesn't seem to really matter since loss is best in the first step. This appears to by a byproduct of our loss defintion in the training loop vs. validation loop. Ideally, we'd want the classification loss to be minimized. Perhaps we should experiment to see if minimizing training loss can help? I suspect it won't, since the side quests might counter the main quests, or we might get stuck in oscillation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca3ea2-fd60-4e54-8942-33172e4de452",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43901c32-73a7-4236-876a-fd802d9a0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(MODEL_NAME))\n",
    "model.eval()  # again currently a no-op\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_bar = tqdm(test_loader, desc=f\"Evaluation\")\n",
    "    for batch in test_bar:\n",
    "        images, labels, _, _, _ = batch\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        classification_out, _, _, _ = model(images)\n",
    "\n",
    "        # stats\n",
    "        _, predicted = torch.max(classification_out, 1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "test_accuracy = 100 * test_correct / test_total\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791135f-f3ea-4c9c-911c-114956c71935",
   "metadata": {},
   "source": [
    "# Exploring Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ecb45-86cb-442a-9d7d-015bacf2ca92",
   "metadata": {},
   "source": [
    "## Visualizing Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06931433-abf0-4774-8a3f-44d0c2ab75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_layer_weights = np.abs(model.horizontal_layer.weight[0].reshape(28, 28).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed217912-7b4f-433a-9349-83709d2dd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(horizontal_layer_weights, \"Horizontal Layer Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ed4c4-b898-4cde-8404-928719681d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_layer_weights = np.abs(model.vertical_layer.weight[0].reshape(28, 28).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb22e2-7093-46c9-b83c-393340925b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(vertical_layer_weights, \"Vertical Layer Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7be8a-1fcd-4811-a264-22f6c1494840",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_layer_weights = np.abs(model.curve_layer.weight[0].reshape(28, 28).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506bc8c7-ee8e-44bb-ad28-dd4d556c3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(curve_layer_weights, \"Curve Layer Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215db4e3-fb2d-4630-b687-5a7c5966eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_layer_weights = np.abs(model.classification_layer.weight[0].reshape(28, 28).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a5cc7-5f9f-448c-b684-542296f8b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_image(classification_layer_weights, \"Classification Layer Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fc096-70d0-4013-97b4-482b7b981ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
